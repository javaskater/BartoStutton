## 1.1 page 23
* explains that action can modify subsequent Rewards
## 1.3 page 28
* policy: function or lookup table StatesxAction --> Values ?
  * specifying probailities for each action
* the Reward: on each step a single number called the reward is sent !!
  * state x action --> reward ?
* the value function is the reward in the long run
  * _after taking into account the states that are likely to follow and the rewards available in those states_
* Action that brig states of highest value not highest reward
* _For example, given a state and action, the model might predict the resultant next state and next reward_ 